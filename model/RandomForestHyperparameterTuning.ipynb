{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest HyperParameter Tuning\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults arameters:\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 91,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(random_state = 91)\n",
    "\n",
    "print('Defaults arameters:')\n",
    "pprint(forest.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters to tune**\n",
    "\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "- bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "\n",
    "# Loading our data \n",
    "\n",
    "- Selected features and model from model exercice (see **model classif selection.ipynb**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25\n",
      "Test substations selected: \n",
      "['DC_EPA', 'McMillan 1', '14th & S ST NW A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\colla\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\users\\colla\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigtable.csv\")\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep]#.astype(np.float64).\n",
    "\n",
    "df = clean_dataset(df).reset_index()\n",
    "\n",
    "features = df[[\n",
    "    'x', \n",
    "    'y', \n",
    "    'dayofweek', \n",
    "    'sin_day', \n",
    "    'cos_day',\n",
    "    'sin_year', \n",
    "    'cos_year', \n",
    "    'TEMP', \n",
    "    'cos_wind', \n",
    "    'sin_wind', \n",
    "    'Wind-Rate', \n",
    "    'DEW', \n",
    "    'SKY', \n",
    "    'VIS', \n",
    "    'ATM'\n",
    "]].astype(np.float64)\n",
    "\n",
    "features.loc[:,'dayofweek'] = features['dayofweek'].astype('category')\n",
    "\n",
    "numericColumns = ['x','y',\n",
    "    'dayofweek', 'sin_day', 'cos_day', 'sin_year', 'cos_year', \n",
    "    'TEMP', 'cos_wind', 'sin_wind', 'Wind-Rate', 'DEW', 'SKY', 'VIS',  'ATM'\n",
    "    ]\n",
    "categoricalColumns = ['dayofweek']\n",
    "\n",
    "gs = df[['station_id']]\n",
    "\n",
    "labels = df[[\n",
    "    'pm25',\n",
    "    'AQI_VALUE', #pm25 transformed using EPA methodology\n",
    "    'AQI_class'  #pm25 transformed into EPA categorical class\n",
    "]]\n",
    "\n",
    "labels.loc[:,\"polluted\"] = (labels.loc[:,\"AQI_class\"] != \"Good\")\n",
    "\n",
    "y=labels[\"polluted\"]\n",
    "X=features\n",
    "\n",
    "def tts_gs(X, y, gs, test_size):\n",
    "    stations = gs[\"station_id\"].unique()\n",
    "    nb_stations = len(stations) * test_size\n",
    "    print(nb_stations)\n",
    "    my_randoms = random.sample(list(stations), int(nb_stations))\n",
    "    filters = gs[\"station_id\"].isin(my_randoms)\n",
    "    print('Test substations selected: ')\n",
    "    print(my_randoms)\n",
    "    return X[~filters], X[filters], y[~filters], y[filters]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = tts_gs(X, y, gs, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__bootstrap': [True, False],\n",
      " 'estimator__max_depth': [10,\n",
      "                          21,\n",
      "                          33,\n",
      "                          45,\n",
      "                          57,\n",
      "                          69,\n",
      "                          80,\n",
      "                          92,\n",
      "                          104,\n",
      "                          116,\n",
      "                          128,\n",
      "                          140,\n",
      "                          None],\n",
      " 'estimator__max_features': ['auto', 'sqrt'],\n",
      " 'estimator__min_samples_leaf': [1, 2, 3, 5],\n",
      " 'estimator__min_samples_split': [2, 3, 5, 8],\n",
      " 'estimator__n_estimators': [100,\n",
      "                             222,\n",
      "                             344,\n",
      "                             466,\n",
      "                             588,\n",
      "                             711,\n",
      "                             833,\n",
      "                             955,\n",
      "                             1077,\n",
      "                             1200]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 140, num = 12)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'estimator__n_estimators': n_estimators,\n",
    "               'estimator__max_features': max_features,\n",
    "               'estimator__max_depth': max_depth,\n",
    "               'estimator__min_samples_split': min_samples_split,\n",
    "               'estimator__min_samples_leaf': min_samples_leaf,\n",
    "               'estimator__bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 503.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ColumnTransformer',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(memory=None,\n",
       "                                                                                        steps=[('scaler',\n",
       "                                                                                                StandardScaler(copy=True,\n",
       "                                                                                                               with_mean=True,\n",
       "                                                                                                               with_std=True))],\n",
       "                                                                                        verbose=False),\n",
       "                                                                               ['x',\n",
       "                                                                                'y',\n",
       "                                                                                'dayofweek',\n",
       "                                                                                'sin_d...\n",
       "                                        'estimator__max_depth': [10, 21, 33, 45,\n",
       "                                                                 57, 69, 80, 92,\n",
       "                                                                 104, 116, 128,\n",
       "                                                                 140, None],\n",
       "                                        'estimator__max_features': ['auto',\n",
       "                                                                    'sqrt'],\n",
       "                                        'estimator__min_samples_leaf': [1, 2, 3,\n",
       "                                                                        5],\n",
       "                                        'estimator__min_samples_split': [2, 3,\n",
       "                                                                         5, 8],\n",
       "                                        'estimator__n_estimators': [100, 222,\n",
       "                                                                    344, 466,\n",
       "                                                                    588, 711,\n",
       "                                                                    833, 955,\n",
       "                                                                    1077,\n",
       "                                                                    1200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=91, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#categorical_features = categoricalColumns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "model = Pipeline([\n",
    "     (\"ColumnTransformer\", ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numericColumns),\n",
    "            ('cat', categorical_transformer, categoricalColumns)\n",
    "        ])),\n",
    "     ('estimator', RandomForestClassifier(random_state = 91))\n",
    "])\n",
    "\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=91, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = sum(predictions != test_labels)\n",
    "    trues = sum((test_labels == True))\n",
    "    falses = sum((test_labels == False))\n",
    "    true_positives = sum((predictions == test_labels) & (test_labels == True))\n",
    "    true_negatives = sum((predictions == test_labels) & (test_labels == False))\n",
    "    false_positives = sum((predictions != test_labels) & (test_labels == True))\n",
    "    false_negatives = sum((predictions != test_labels) & (test_labels == False))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f}.'.format(errors / len(test_labels)))\n",
    "    print('Average true_positives: {:0.4f}.'.format(true_positives / len(test_labels)))\n",
    "    print('Average true_negatives: {:0.4f}.'.format(true_negatives / len(test_labels)))\n",
    "    print('Average false_positives: {:0.4f}.'.format(false_positives / len(test_labels)))\n",
    "    print('Average false_negatives: {:0.4f}.'.format(errors / len(test_labels)))\n",
    "    \n",
    "    #Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "    trues_precision = (true_positives / (true_positives + false_positives))\n",
    "    falses_precision = (true_negatives / (true_negatives + false_negatives))\n",
    "    print('Precision for Trues (is Polluted) = {:0.4f}%.'.format(100*trues_precision))\n",
    "    print('Precision for False (not Polluted) {:0.24}%.'.format(100*falses_precision))\n",
    "    \n",
    "    #Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "    trues_recall = true_positives / (true_positives + false_negatives)\n",
    "    falses_recall = true_negatives / (true_negatives + false_positives)\n",
    "    print('(!)Precision for Trues (is Polluted) = {:0.4f}%.'.format(100*trues_recall))\n",
    "    print('Precision for False (not Polluted) {:0.4f}%.'.format(100*falses_recall))\n",
    "    \n",
    "    #F-1 = (2 * Precision * Recall) / (Precision + Recall)\n",
    "    trues_f1 = (2 * trues_precision * trues_recall) /(trues_precision + trues_recall)\n",
    "    falses_f1 = (2 * falses_precision * falses_recall) /(falses_precision + falses_recall)\n",
    "    print('(!)F1 for Trues (is Polluted) = {:0.4f}%.'.format(100*trues_f1))\n",
    "    print('F1 for False (not Polluted) {:0.4f}%.'.format(100*falses_f1))\n",
    "    \n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"{}: {:0.4f}%\".format(model.__class__.__name__, 100 * f1_score(test_labels, predictions)))\n",
    "    \n",
    "    return f1_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1933.\n",
      "Average true_positives: 0.1433.\n",
      "Average true_negatives: 0.6634.\n",
      "Average false_positives: 0.0073.\n",
      "Average false_negatives: 0.1933.\n",
      "Precision for Trues (is Polluted) = 95.1629%.\n",
      "Precision for False (not Polluted) 78.1033219871601573913722%.\n",
      "(!)Precision for Trues (is Polluted) = 43.5145%.\n",
      "Precision for False (not Polluted) 98.9141%.\n",
      "(!)F1 for Trues (is Polluted) = 59.7208%.\n",
      "F1 for False (not Polluted) 87.2854%.\n",
      "Pipeline: 59.7208%\n"
     ]
    }
   ],
   "source": [
    "#base_model = RandomForestClassifier(n_estimators = 10, random_state = 91)\n",
    "model.fit(Xtrain, ytrain)\n",
    "base_accuracy = evaluate(model, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.2073.\n",
      "Average true_positives: 0.1319.\n",
      "Average true_negatives: 0.6608.\n",
      "Average false_positives: 0.0187.\n",
      "Average false_negatives: 0.2073.\n",
      "Precision for Trues (is Polluted) = 87.6033%.\n",
      "Precision for False (not Polluted) 77.7974061786376012150868%.\n",
      "(!)Precision for Trues (is Polluted) = 41.1556%.\n",
      "Precision for False (not Polluted) 97.2530%.\n",
      "(!)F1 for Trues (is Polluted) = 56.0019%.\n",
      "F1 for False (not Polluted) 86.4440%.\n",
      "Pipeline: 56.0019%\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -6.23%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__n_estimators': 100,\n",
       " 'estimator__min_samples_split': 8,\n",
       " 'estimator__min_samples_leaf': 3,\n",
       " 'estimator__max_features': 'auto',\n",
       " 'estimator__max_depth': 116,\n",
       " 'estimator__bootstrap': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ColumnTransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('num',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('scaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['x', 'y', 'dayofweek', 'sin_day', 'cos_day',\n",
       "                                     'sin_year', 'cos_year', 'TEMP', 'cos_wind',\n",
       "                                     'sin_wind', 'Wind-Rate', 'DEW', 'SKY', 'VIS',\n",
       "                                     'ATM']),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('onehot',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='ignore',\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['dayofweek'])],\n",
       "                     verbose=False)),\n",
       "  ('estimator',\n",
       "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                          criterion='gini', max_depth=None, max_features='auto',\n",
       "                          max_leaf_nodes=None, max_samples=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_jobs=None, oob_score=False, random_state=91, verbose=0,\n",
       "                          warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'ColumnTransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('num',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('scaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['x', 'y', 'dayofweek', 'sin_day', 'cos_day',\n",
       "                                   'sin_year', 'cos_year', 'TEMP', 'cos_wind',\n",
       "                                   'sin_wind', 'Wind-Rate', 'DEW', 'SKY', 'VIS',\n",
       "                                   'ATM']),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('onehot',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='ignore',\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['dayofweek'])],\n",
       "                   verbose=False),\n",
       " 'estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=91, verbose=0,\n",
       "                        warm_start=False),\n",
       " 'ColumnTransformer__n_jobs': None,\n",
       " 'ColumnTransformer__remainder': 'drop',\n",
       " 'ColumnTransformer__sparse_threshold': 0.3,\n",
       " 'ColumnTransformer__transformer_weights': None,\n",
       " 'ColumnTransformer__transformers': [('num',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('scaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False),\n",
       "   ['x',\n",
       "    'y',\n",
       "    'dayofweek',\n",
       "    'sin_day',\n",
       "    'cos_day',\n",
       "    'sin_year',\n",
       "    'cos_year',\n",
       "    'TEMP',\n",
       "    'cos_wind',\n",
       "    'sin_wind',\n",
       "    'Wind-Rate',\n",
       "    'DEW',\n",
       "    'SKY',\n",
       "    'VIS',\n",
       "    'ATM']),\n",
       "  ('cat',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('onehot',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='ignore', sparse=True))],\n",
       "            verbose=False),\n",
       "   ['dayofweek'])],\n",
       " 'ColumnTransformer__verbose': False,\n",
       " 'ColumnTransformer__num': Pipeline(memory=None,\n",
       "          steps=[('scaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'ColumnTransformer__cat': Pipeline(memory=None,\n",
       "          steps=[('onehot',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='ignore', sparse=True))],\n",
       "          verbose=False),\n",
       " 'ColumnTransformer__num__memory': None,\n",
       " 'ColumnTransformer__num__steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'ColumnTransformer__num__verbose': False,\n",
       " 'ColumnTransformer__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'ColumnTransformer__num__scaler__copy': True,\n",
       " 'ColumnTransformer__num__scaler__with_mean': True,\n",
       " 'ColumnTransformer__num__scaler__with_std': True,\n",
       " 'ColumnTransformer__cat__memory': None,\n",
       " 'ColumnTransformer__cat__steps': [('onehot',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='ignore', sparse=True))],\n",
       " 'ColumnTransformer__cat__verbose': False,\n",
       " 'ColumnTransformer__cat__onehot': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='ignore', sparse=True),\n",
       " 'ColumnTransformer__cat__onehot__categories': 'auto',\n",
       " 'ColumnTransformer__cat__onehot__drop': None,\n",
       " 'ColumnTransformer__cat__onehot__dtype': numpy.float64,\n",
       " 'ColumnTransformer__cat__onehot__handle_unknown': 'ignore',\n",
       " 'ColumnTransformer__cat__onehot__sparse': True,\n",
       " 'estimator__bootstrap': True,\n",
       " 'estimator__ccp_alpha': 0.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__criterion': 'gini',\n",
       " 'estimator__max_depth': None,\n",
       " 'estimator__max_features': 'auto',\n",
       " 'estimator__max_leaf_nodes': None,\n",
       " 'estimator__max_samples': None,\n",
       " 'estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__min_impurity_split': None,\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 2,\n",
       " 'estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__oob_score': False,\n",
       " 'estimator__random_state': 91,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf_random.best_estimator_, 'best_random.model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
